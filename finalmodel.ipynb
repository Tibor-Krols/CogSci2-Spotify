{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4851fdd4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ef8168e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "/Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import nltk\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error #add rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1896da",
   "metadata": {},
   "source": [
    "# Reading files and making it regressionable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9e51902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('merged_cleaned_sentiment_train.csv').drop(['pos','neg','neu', 'compound'], axis = 1)\n",
    "df_val = pd.read_csv('merged_cleaned_sentiment_validation.csv').drop(['pos','neg','neu', 'compound'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf147c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, pd.read_csv('lyrics_features_train.csv')], axis=1)\n",
    "df_val = pd.concat([df_val, pd.read_csv('lyrics_features_val.csv')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a7a358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, pd.get_dummies(df_train.key, drop_first = True, prefix = 'key')], axis=1)\n",
    "df_val = pd.concat([df_val, pd.get_dummies(df_val.key, drop_first = True, prefix = 'key')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "512cfc24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['Unnamed: 0', 'artist', 'trackname', 'id', 'time_signature', 'lyrics', 'lyrics_cleaned'], axis=1)\n",
    "df_val = df_val.drop(['Unnamed: 0', 'artist', 'trackname', 'id', 'time_signature', 'lyrics', 'lyrics_cleaned'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f979108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_val = df_val.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "364b68fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        6\n",
       "1        5\n",
       "2        5\n",
       "3        9\n",
       "4        9\n",
       "        ..\n",
       "7590     2\n",
       "7591     2\n",
       "7592    11\n",
       "7593     1\n",
       "7594     6\n",
       "Name: key, Length: 7595, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd5f2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get cross validation scores\n",
    "def get_cv_scores(model, X_train, y_train):\n",
    "    scores = cross_val_score(model,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             cv=5,\n",
    "                             scoring='r2')\n",
    "    \n",
    "    print('CV Mean: ', np.mean(scores))\n",
    "    print('STD: ', np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275770ba",
   "metadata": {},
   "source": [
    "# Splitting the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc2128c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     train set\n",
    "X_train = df_train.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "y_train_valence = df_train.y_valence.values \n",
    "y_train_arousal = df_train.y_arousal.values\n",
    "    \n",
    "#     validation set\n",
    "X_val = df_val.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "y_val_valence = df_val.y_valence.values \n",
    "y_val_arousal = df_val.y_arousal.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3a6bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['y_valence', 'y_arousal'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a867712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_regression(X, y_1, y_2, X_validation, y_1_validation, y_2_validation, optimize = False):\n",
    "    \n",
    "\n",
    "    # parameters\n",
    "    param_grid = {'fit_intercept':[True,False], 'positive':[True, False]}\n",
    "    \n",
    "    # Initialize model for Grid search\n",
    "    lr_val = LinearRegression()\n",
    "    lr_arou = LinearRegression()\n",
    "    \n",
    "    # Grid search\n",
    "    clf_vale = GridSearchCV(lr_val, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    clf_arou = GridSearchCV(lr_arou, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "\n",
    "    # Print best results on training data    \n",
    "    clf_vale.fit(X, y_1)\n",
    "    clf_arou.fit(X, y_2)\n",
    "    \n",
    "    # Print best results on training data\n",
    "    # add new lines to separate rows\n",
    "    print()\n",
    "    print(\"Best parameter for Valence (CV score=%0.3f):\" % clf_vale.best_score_)\n",
    "    print(clf_vale.best_params_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Best parameter for Arousal (CV score=%0.3f):\" % clf_arou.best_score_)\n",
    "    print(clf_arou.best_params_)\n",
    "    print()\n",
    "\n",
    "\n",
    "    #Initialize models with best parameters\n",
    "    lr_val_top = LinearRegression(fit_intercept=clf_vale.best_params_['fit_intercept'],  \n",
    "                                    positive = clf_vale.best_params_['positive'])\n",
    "    lr_arou_top = LinearRegression(fit_intercept=clf_arou.best_params_['fit_intercept'],  \n",
    "                                    positive = clf_arou.best_params_['positive'])\n",
    "\n",
    "    # get cross val scores for models \n",
    "    get_cv_scores(lr_val_top, X, y_1)\n",
    "    get_cv_scores(lr_arou_top, X, y_2)\n",
    "\n",
    "\n",
    "    #fit optimal models to train data \n",
    "    lr_val_fit = lr_val_top.fit(X, y_1)\n",
    "    lr_arou_fit = lr_arou_top.fit(X, y_2)\n",
    "    \n",
    "    # validation scores \n",
    "    r2_validation_valence = lr_val_fit.score(X_validation, y_1_validation)\n",
    "    r2_validation_arousal = lr_arou_fit.score(X_validation, y_2_validation)\n",
    "    \n",
    "    print()\n",
    "    print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "    print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "    \n",
    "    return clf_vale.best_params_, clf_arou.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e211ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_forest_regression(X, y_1, y_2, X_validation, y_1_validation, y_2_validation):\n",
    "    \n",
    "    # Initialize models\n",
    "    rf_val = RandomForestRegressor(random_state=0)\n",
    "    rf_arou = RandomForestRegressor(random_state=0)\n",
    "    \n",
    "    param_grid = { \n",
    "    'n_estimators': [100, 500],\n",
    "    'max_depth' : [5,10, 15]\n",
    "    }\n",
    "\n",
    "    # Grid search\n",
    "    clf_vale = GridSearchCV(rf_val, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    clf_arou = GridSearchCV(rf_arou, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "\n",
    "    # Print best results on training data    \n",
    "    clf_vale.fit(X, y_1)\n",
    "    clf_arou.fit(X, y_2)\n",
    "\n",
    "    # Print best results on training data\n",
    "    print()\n",
    "    print(\"Best parameter for Valence (CV score=%0.3f):\" % clf_vale.best_score_)\n",
    "    print(clf_vale.best_params_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Best parameter for Arousal (CV score=%0.3f):\" % clf_arou.best_score_)\n",
    "    print(clf_arou.best_params_)\n",
    "\n",
    "\n",
    "    #Initialize models with best parameters\n",
    "    rf_val_top = RandomForestRegressor(n_estimators = clf_vale.best_params_['n_estimators'], \n",
    "                                        max_depth = clf_vale.best_params_['max_depth'], random_state=0)\n",
    "    rf_arou_top = RandomForestRegressor(n_estimators = clf_arou.best_params_['n_estimators'], \n",
    "                                        max_depth = clf_arou.best_params_['max_depth'], random_state=0)\n",
    "    \n",
    "\n",
    "    # get cross val scores\n",
    "    get_cv_scores(rf_val_top, X, y_1)\n",
    "    get_cv_scores(rf_arou_top, X, y_2)\n",
    "\n",
    "    rf_val_fit = rf_val_top.fit(X, y_1)\n",
    "    rf_arou_fit = rf_arou_top.fit(X, y_2)\n",
    "    \n",
    "    r2_validation_valence = rf_val_fit.score(X_validation, y_1_validation)\n",
    "    r2_validation_arousal = rf_arou_fit.score(X_validation, y_2_validation)\n",
    "\n",
    "    print()\n",
    "    print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "    print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "    \n",
    "    \n",
    "    return clf_vale.best_params_, clf_arou.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57838728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_svr(X, y_1, y_2, X_validation, y_1_validation, y_2_validation):\n",
    "\n",
    "    #Standardizing\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X_validation = scaler.transform(X_validation)\n",
    "\n",
    "    # Train model\n",
    "    svr_val = SVR()\n",
    "    svr_arou = SVR()\n",
    "    \n",
    "    param_grid = {'kernel' : ('linear', 'rbf'),\n",
    "                  'C' : [1,5,10]\n",
    "                 }\n",
    "\n",
    "    # Grid search\n",
    "    clf_vale = GridSearchCV(svr_val, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    clf_arou = GridSearchCV(svr_arou, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "\n",
    "    # Print best results on training data    \n",
    "    clf_vale.fit(X, y_1)\n",
    "    clf_arou.fit(X, y_2)\n",
    "    \n",
    "    # Print best results on training data\n",
    "    # add new lines to separate rows\n",
    "    print()\n",
    "    print(\"Best parameter for Valence (CV score=%0.3f):\" % clf_vale.best_score_)\n",
    "    print(clf_vale.best_params_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Best parameter for Arousal (CV score=%0.3f):\" % clf_arou.best_score_)\n",
    "    print(clf_arou.best_params_)\n",
    "    print()\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    svr_val_top = SVR(kernel = clf_vale.best_params_['kernel'], C = clf_vale.best_params_['C'], \n",
    "                        degree= clf_vale.best_params_['degree'], coef0 = clf_vale.best_params_['coef0'],\n",
    "                        gamma = clf_vale.best_params_['gamma'])\n",
    "    svr_arou_top = SVR(kernel = clf_arou.best_params_['kernel'], C = clf_arou.best_params_['C'], \n",
    "                        degree= clf_arou.best_params_['degree'], coef0 = clf_arou.best_params_['coef0'],\n",
    "                        gamma = clf_arou.best_params_['gamma'])\n",
    "\n",
    "\n",
    "    # get cross val scores\n",
    "    get_cv_scores(svr_val_top, X, y_1)\n",
    "    get_cv_scores(svr_arou_top, X, y_2)\n",
    "    \n",
    "    r2_validation_valence = svr_val_top.score(X_validation, y_1_validation)\n",
    "    r2_validation_arousal = svr_arou_top.score(X_validation, y_2_validation)\n",
    "    \n",
    "    print()\n",
    "    print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "    print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "\n",
    "\n",
    "    return clf_vale.best_params_, clf_arou.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "467c67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mlp(X, y_1, y_2, X_validation, y_1_validation, y_2_validation):\n",
    "\n",
    "    # Normalization\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_validation = scaler.fit_transform(X_validation)\n",
    "\n",
    "    # Initialize model\n",
    "    mlp_val = MLPRegressor(random_state = 2)\n",
    "    mlp_arou = MLPRegressor(random_state = 2)\n",
    "    \n",
    "    param_grid = {'hidden_layer_sizes':[(5), (10), (15), (5,5), (10,10), (15,15), (5,5,5), (10,10,10), (15,15,15)], \n",
    "    'max_iter':[500, 1000, 2000, 2500]}\n",
    "\n",
    "    # Grid search\n",
    "    clf_vale = GridSearchCV(mlp_val, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    clf_arou = GridSearchCV(mlp_arou, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "\n",
    "\n",
    "    # Print best results on training data    \n",
    "    clf_vale.fit(X, y_1)\n",
    "    clf_arou.fit(X, y_2)\n",
    "    \n",
    "    # Print best results on training data\n",
    "    # add new lines to separate rows\n",
    "    print()\n",
    "    print(\"Best parameter for Valence (CV score=%0.3f):\" % clf_vale.best_score_)\n",
    "    print(clf_vale.best_params_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Best parameter for Arousal (CV score=%0.3f):\" % clf_arou.best_score_)\n",
    "    print(clf_arou.best_params_)\n",
    "    print()\n",
    "\n",
    "\n",
    "    #Train model with best params\n",
    "    mlp_val_top = MLPRegressor(hidden_layer_sizes=clf_vale.best_params_['hidden_layer_sizes'], max_iter=clf_vale.best_params_['max_iter'], random_state = 2)\n",
    "    mlp_arou_top = MLPRegressor(hidden_layer_sizes=clf_arou.best_params_['hidden_layer_sizes'], max_iter=clf_arou.best_params_['max_iter'], random_state = 2)\n",
    "\n",
    "    # get cross val scores \n",
    "    get_cv_scores(mlp_val_top, X, y_1)\n",
    "    get_cv_scores(mlp_arou_top, X, y_2)\n",
    "\n",
    "    mlp_val_fit = mlp_val_top.fit(X, y_1)\n",
    "    mlp_arou_fit = mlp_arou_top.fit(X, y_2)\n",
    "    \n",
    "    r2_validation_valence = mlp_val_fit.score(X_validation, y_1_validation)\n",
    "    r2_validation_arousal = mlp_arou_fit.score(X_validation, y_2_validation)\n",
    "    \n",
    "    print()\n",
    "    print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "    print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "\n",
    "    \n",
    "    return clf_vale.best_params_, clf_arou.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14a6a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "\n",
      "Best parameter for Valence (CV score=0.133):\n",
      "{'max_depth': 5, 'n_estimators': 500}\n",
      "\n",
      "Best parameter for Arousal (CV score=0.185):\n",
      "{'max_depth': 5, 'n_estimators': 500}\n",
      "CV Mean:  0.13275661965988045\n",
      "STD:  0.011784880327224306\n",
      "CV Mean:  0.18475573779507143\n",
      "STD:  0.02493407497896191\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'rf_arou_fit' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000014?line=0'>1</a>\u001b[0m do_forest_regression(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)\n",
      "\u001b[1;32m/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb Cell 14'\u001b[0m in \u001b[0;36mdo_forest_regression\u001b[0;34m(X, y_1, y_2, X_validation, y_1_validation, y_2_validation)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000012?line=49'>50</a>\u001b[0m get_cv_scores(rf_arou_top, X, y_2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000012?line=51'>52</a>\u001b[0m rf_val_fit \u001b[39m=\u001b[39m rf_val_top\u001b[39m.\u001b[39mfit(X, y_1)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000012?line=52'>53</a>\u001b[0m rf_arou_fit \u001b[39m=\u001b[39m rf_arou_fit\u001b[39m.\u001b[39mfit(X, y_2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000012?line=54'>55</a>\u001b[0m r2_validation_valence \u001b[39m=\u001b[39m rf_val_fit\u001b[39m.\u001b[39mscore(X_validation, y_1_validation)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000012?line=55'>56</a>\u001b[0m r2_validation_arousal \u001b[39m=\u001b[39m rf_arou_fit\u001b[39m.\u001b[39mscore(X_validation, y_2_validation)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'rf_arou_fit' referenced before assignment"
     ]
    }
   ],
   "source": [
    "do_forest_regression(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed181599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation score for Valence: 0.13244754474966047\n",
      "Validation score for Arousal: 0.22954186143541289\n"
     ]
    }
   ],
   "source": [
    "rf_val_top = RandomForestRegressor(n_estimators = 500, \n",
    "                                        max_depth = 5, random_state=0)\n",
    "rf_arou_top = RandomForestRegressor(n_estimators = 500, \n",
    "                                        max_depth = 5, random_state=0)\n",
    "\n",
    "rf_val_fit = rf_val_top.fit(X_train, y_train_valence)\n",
    "rf_arou_fit = rf_arou_top.fit(X_train, y_train_arousal)\n",
    "\n",
    "r2_validation_valence = rf_val_fit.score(X_val, y_val_valence)\n",
    "r2_validation_arousal = rf_arou_fit.score(X_val, y_val_arousal)\n",
    "\n",
    "print()\n",
    "print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0b706",
   "metadata": {},
   "source": [
    "    Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
    "    Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
    "\n",
    "    Best parameter for Valence (CV score=0.133):\n",
    "    {'max_depth': 5, 'n_estimators': 500}\n",
    "\n",
    "    Best parameter for Arousal (CV score=0.185):\n",
    "    {'max_depth': 5, 'n_estimators': 500}\n",
    "\n",
    "    CV Mean:  0.13275661965988045\n",
    "    STD:  0.011784880327224306\n",
    "    \n",
    "    CV Mean:  0.18475573779507143\n",
    "    STD:  0.02493407497896191\n",
    "\n",
    "    Validation score for Valence: 0.13244754474966047\n",
    "    Validation score for Arousal: 0.22954186143541289 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d477cd",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eb39853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Best parameter for Valence (CV score=0.111):\n",
      "{'fit_intercept': True, 'positive': True}\n",
      "\n",
      "Best parameter for Arousal (CV score=0.140):\n",
      "{'fit_intercept': True, 'positive': True}\n",
      "\n",
      "CV Mean:  0.11111028455728592\n",
      "STD:  0.01146729431981076\n",
      "CV Mean:  0.14019888233177344\n",
      "STD:  0.016407509678998546\n",
      "\n",
      "Validation score for Valence: 0.10736294104767685\n",
      "Validation score for Arousal: 0.14409979172722753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_intercept': True, 'positive': True},\n",
       " {'fit_intercept': True, 'positive': True})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_regression(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379e45b",
   "metadata": {},
   "source": [
    "    Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
    "    Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
    "\n",
    "    Best parameter for Valence (CV score=0.110):\n",
    "    {'fit_intercept': True, 'positive': True}\n",
    "\n",
    "    Best parameter for Arousal (CV score=0.140):\n",
    "    {'fit_intercept': True, 'positive': True}\n",
    "\n",
    "    CV Mean:  0.10971270746043267\n",
    "    STD:  0.011520359485346096\n",
    "    CV Mean:  0.13982572692153966\n",
    "    STD:  0.017046339734464865\n",
    "\n",
    "    Validation score for Valence: 0.10470671333163195\n",
    "    Validation score for Arousal: 0.1431543974033288\n",
    "    ({'fit_intercept': True, 'positive': True},\n",
    "    {'fit_intercept': True, 'positive': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b5ad3a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_partial = pd.read_csv('merged_cleaned_sentiment_train.csv')\n",
    "df_train_partial = pd.concat([df_train_partial, pd.get_dummies(df_train.key, drop_first = True, prefix = 'key')], axis=1)\n",
    "df_train_partial = df_train_partial.drop(['Unnamed: 0', 'artist', 'trackname', 'id', 'time_signature', 'lyrics', 'lyrics_cleaned', 'key'], axis=1)\n",
    "\n",
    "\n",
    "df_val_partial = pd.read_csv('merged_cleaned_sentiment_validation.csv')\n",
    "df_val_partial = pd.concat([df_val_partial, pd.get_dummies(df_train.key, drop_first = True, prefix = 'key')], axis=1)\n",
    "df_val_partial = df_val_partial.drop(['Unnamed: 0', 'artist', 'trackname', 'id', 'time_signature', 'lyrics', 'lyrics_cleaned', 'key'], axis=1)\n",
    "\n",
    "df_train_partial = pd.concat([df_train_partial, pd.read_csv('lyrics_features_train.csv').iloc[:, :-200]], axis=1).dropna()\n",
    "df_val_partial = pd.concat([df_val_partial, pd.read_csv('lyrics_features_val.csv').iloc[:, :-200]], axis=1).dropna()\n",
    "\n",
    "#     train set\n",
    "X_train_partial = df_train_partial.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "y_train_partial_valence = df_train_partial.y_valence.values \n",
    "y_train_partial_arousal = df_train_partial.y_arousal.values\n",
    "    \n",
    "#     validation set\n",
    "X_val_partial = df_val_partial.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "y_val_partial_valence = df_val_partial.y_valence.values \n",
    "y_val_partial_arousal = df_val_partial.y_arousal.values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f3dadfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7596, 25)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6fb28320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['danceability', 'energy', 'loudness', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       ...\n",
       "       'tfidf_pca_141', 'tfidf_pca_142', 'tfidf_pca_143', 'tfidf_pca_144',\n",
       "       'tfidf_pca_145', 'tfidf_pca_146', 'tfidf_pca_147', 'tfidf_pca_148',\n",
       "       'tfidf_pca_149', 'tfidf_pca_150'],\n",
       "      dtype='object', length=182)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_partial.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1335c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Best parameter for Valence (CV score=0.164):\n",
      "{'fit_intercept': True, 'positive': True}\n",
      "\n",
      "Best parameter for Arousal (CV score=0.156):\n",
      "{'fit_intercept': True, 'positive': True}\n",
      "\n",
      "CV Mean:  0.16360860461294166\n",
      "STD:  0.019479749276111142\n",
      "CV Mean:  0.1555347105221878\n",
      "STD:  0.015044826818414521\n",
      "\n",
      "Validation score for Valence: 0.15323139981799105\n",
      "Validation score for Arousal: 0.1747622664978824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_intercept': True, 'positive': True},\n",
       " {'fit_intercept': True, 'positive': True})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_regression(X_train_partial, y_train_partial_valence, y_train_partial_arousal, X_val_partial, y_val_partial_valence, y_val_partial_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "afbe97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_partial = pd.read_csv('merged_cleaned_sentiment_train.csv')\n",
    "df_train_partial = pd.concat([df_train_partial, pd.get_dummies(df_train.key, drop_first = True, prefix = 'key')], axis=1).dropna()\n",
    "df_train_partial = df_train_partial.drop(['Unnamed: 0', 'artist', 'trackname', 'id', 'time_signature', 'lyrics', 'lyrics_cleaned', 'key'], axis=1)\n",
    "\n",
    "\n",
    "df_val_partial = pd.read_csv('merged_cleaned_sentiment_validation.csv')\n",
    "df_val_partial = pd.concat([df_val_partial, pd.get_dummies(df_train.key, drop_first = True, prefix = 'key')], axis=1).dropna()\n",
    "df_val_partial = df_val_partial.drop(['Unnamed: 0', 'artist', 'trackname', 'id', 'time_signature', 'lyrics', 'lyrics_cleaned', 'key'], axis=1)\n",
    "\n",
    "#     train set\n",
    "X_train_partial = df_train_partial.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "y_train_partial_valence = df_train_partial.y_valence.values \n",
    "y_train_partial_arousal = df_train_partial.y_arousal.values\n",
    "    \n",
    "#     validation set\n",
    "X_val_partial = df_val_partial.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "y_val_partial_valence = df_val_partial.y_valence.values \n",
    "y_val_partial_arousal = df_val_partial.y_arousal.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59c892b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Best parameter for Valence (CV score=0.174):\n",
      "{'fit_intercept': True, 'positive': True}\n",
      "\n",
      "Best parameter for Arousal (CV score=0.169):\n",
      "{'fit_intercept': False, 'positive': False}\n",
      "\n",
      "CV Mean:  0.1739597914628858\n",
      "STD:  0.01904918788782633\n",
      "CV Mean:  0.16927345119522438\n",
      "STD:  0.02171195419566874\n",
      "\n",
      "Validation score for Valence: 0.15811334175537117\n",
      "Validation score for Arousal: 0.19883809186851342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_intercept': True, 'positive': True},\n",
       " {'fit_intercept': False, 'positive': False})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_regression(X_train_partial, y_train_partial_valence, y_train_partial_arousal, X_val_partial, y_val_partial_valence, y_val_partial_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a72c112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000016?line=0'>1</a>\u001b[0m do_svr(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)\n",
      "\u001b[1;32m/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb Cell 15'\u001b[0m in \u001b[0;36mdo_svr\u001b[0;34m(X, y_1, y_2, X_validation, y_1_validation, y_2_validation)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000013?line=24'>25</a>\u001b[0m clf_arou \u001b[39m=\u001b[39m GridSearchCV(svr_arou, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000013?line=25'>26</a>\u001b[0m                         param_grid, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000013?line=26'>27</a>\u001b[0m                         scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr2\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000013?line=27'>28</a>\u001b[0m                         verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000013?line=28'>29</a>\u001b[0m                         n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000013?line=29'>30</a>\u001b[0m                         return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000013?line=31'>32</a>\u001b[0m \u001b[39m# Print best results on training data    \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000013?line=32'>33</a>\u001b[0m clf_vale\u001b[39m.\u001b[39;49mfit(X, y_1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000013?line=33'>34</a>\u001b[0m clf_arou\u001b[39m.\u001b[39mfit(X, y_2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000013?line=35'>36</a>\u001b[0m \u001b[39m# Print best results on training data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yananikolova/Documents/GitHub/CogSci2-Spotify/finalmodel.ipynb#ch0000013?line=36'>37</a>\u001b[0m \u001b[39m# add new lines to separate rows\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=884'>885</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=885'>886</a>\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=886'>887</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=888'>889</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=890'>891</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=892'>893</a>\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=893'>894</a>\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=894'>895</a>\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=1389'>1390</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=1390'>1391</a>\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=1391'>1392</a>\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=829'>830</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=830'>831</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=831'>832</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=832'>833</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=833'>834</a>\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=834'>835</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=835'>836</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=837'>838</a>\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=838'>839</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=839'>840</a>\u001b[0m         clone(base_estimator),\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=840'>841</a>\u001b[0m         X,\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=841'>842</a>\u001b[0m         y,\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=842'>843</a>\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=843'>844</a>\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=844'>845</a>\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=845'>846</a>\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=846'>847</a>\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=847'>848</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=848'>849</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=849'>850</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=850'>851</a>\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=851'>852</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=852'>853</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=854'>855</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=855'>856</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=856'>857</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=857'>858</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=858'>859</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=859'>860</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py?line=1052'>1053</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py?line=1054'>1055</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py?line=1055'>1056</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py?line=1056'>1057</a>\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py?line=1057'>1058</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py?line=932'>933</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py?line=933'>934</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py?line=934'>935</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py?line=935'>936</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py?line=936'>937</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=538'>539</a>\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=539'>540</a>\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=540'>541</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=541'>542</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=542'>543</a>\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=543'>544</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py?line=436'>437</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py?line=437'>438</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py?line=439'>440</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py?line=441'>442</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py?line=442'>443</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/threading.py?line=309'>310</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/threading.py?line=310'>311</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/threading.py?line=311'>312</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/threading.py?line=312'>313</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/yananikolova/opt/anaconda3/lib/python3.9/threading.py?line=313'>314</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "do_svr(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7f3a2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "Best parameter for Valence (CV score=0.129):\n",
      "{'hidden_layer_sizes': (10, 10), 'max_iter': 500}\n",
      "\n",
      "Best parameter for Arousal (CV score=0.158):\n",
      "{'hidden_layer_sizes': 5, 'max_iter': 500}\n",
      "\n",
      "CV Mean:  0.12862127613817412\n",
      "STD:  0.014345325664449918\n",
      "CV Mean:  0.15809361480244224\n",
      "STD:  0.013992543325221827\n",
      "\n",
      "Validation score for Valence: 0.06403035750427888\n",
      "Validation score for Arousal: 0.19374567585584568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'hidden_layer_sizes': (10, 10), 'max_iter': 500},\n",
       " {'hidden_layer_sizes': 5, 'max_iter': 500})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_mlp(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18724bea",
   "metadata": {},
   "source": [
    "    Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
    "    Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
    "\n",
    "    Best parameter for Valence (CV score=0.129):\n",
    "    {'hidden_layer_sizes': (10, 10), 'max_iter': 500}\n",
    "\n",
    "    Best parameter for Arousal (CV score=0.158):\n",
    "    {'hidden_layer_sizes': 5, 'max_iter': 500}\n",
    "\n",
    "    CV Mean:  0.12862127613817412\n",
    "    STD:  0.014345325664449918\n",
    "    CV Mean:  0.15809361480244224\n",
    "    STD:  0.013992543325221827\n",
    "\n",
    "    Validation score for Valence: 0.06403035750427888\n",
    "    Validation score for Arousal: 0.19374567585584568\n",
    "    ({'hidden_layer_sizes': (10, 10), 'max_iter': 500},\n",
    "    {'hidden_layer_sizes': 5, 'max_iter': 500})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b93966",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66892e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e44659e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 FEATURES\n",
      "CV Mean:  0.1262451176791907\n",
      "STD:  0.012233182074217735\n",
      "CV Mean:  0.1511001193689173\n",
      "STD:  0.018394987112202853\n",
      "\n",
      "10 FEATURES\n",
      "CV Mean:  0.12848109065258234\n",
      "STD:  0.011630560289500033\n",
      "CV Mean:  0.16234581950445054\n",
      "STD:  0.01720335276747698\n",
      "\n",
      "15 FEATURES\n",
      "CV Mean:  0.1287407081579088\n",
      "STD:  0.01136939381647846\n",
      "CV Mean:  0.16269616662621028\n",
      "STD:  0.01690105990297593\n",
      "\n",
      "20 FEATURES\n",
      "CV Mean:  0.13038716144873894\n",
      "STD:  0.011933507116895078\n",
      "CV Mean:  0.1617235276109967\n",
      "STD:  0.016067900547081418\n",
      "\n",
      "25 FEATURES\n",
      "CV Mean:  0.1306106156990735\n",
      "STD:  0.012173101528586356\n",
      "CV Mean:  0.16129697710145624\n",
      "STD:  0.015127846124592396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in [5,10,15,20,25]:\n",
    "\n",
    "    print(i, 'FEATURES')\n",
    "    estimator = LinearRegression(fit_intercept= True, positive= True)\n",
    "    selector = RFE(estimator, n_features_to_select=i, step=1)\n",
    "    selector = selector.fit(X_train, y_train_valence)\n",
    "\n",
    "    estimator2 = LinearRegression(fit_intercept= True, positive= True)\n",
    "    selector2 = RFE(estimator2, n_features_to_select=i, step=1)\n",
    "    selector_arou = selector2.fit(X_train, y_train_arousal)\n",
    "\n",
    "    lr_valence = LinearRegression(fit_intercept= True, positive= True)\n",
    "    lr_arousal = LinearRegression(fit_intercept= True, positive= True)\n",
    "    get_cv_scores(estimator, X_train[:,selector.support_], y_train_valence)\n",
    "    get_cv_scores(estimator, X_train[:,selector_arou.support_], y_train_arousal)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e1f0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 features\n",
    "estimator = LinearRegression(fit_intercept= True, positive= True)\n",
    "selector = RFE(estimator, n_features_to_select=20, step=1)\n",
    "selector = selector.fit(X_train, y_train_valence)\n",
    "\n",
    "estimator2 = LinearRegression(fit_intercept= True, positive= True)\n",
    "selector2 = RFE(estimator2, n_features_to_select=20, step=1)\n",
    "selector_arou = selector2.fit(X_train, y_train_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "47bbf3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_valence = MLPRegressor(hidden_layer_sizes= (10,10), max_iter=500)\n",
    "mlp_arousal = MLPRegressor(hidden_layer_sizes= 5, max_iter=500)\n",
    "mlp_val_fit = mlp_valence.fit(X_train[:,selector.support_], y_train_valence)\n",
    "mlp_arou_fit = mlp_arousal.fit(X_train[:,selector_arou.support_], y_train_arousal)\n",
    "\n",
    "r2_validation_valence = mlp_val_fit.score(X_val[:,selector.support_], y_val_valence)\n",
    "r2_validation_arousal = mlp_arou_fit.score(X_val[:,selector_arou.support_], y_val_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "465cde19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation score for Valence: 0.1188660608771629\n",
      "Validation score for Arousal: 0.18742728449631385\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print()\n",
    "print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "print(f'Validation score for Arousal: {r2_validation_arousal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "122ec7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['danceability', 'valence', 'pos', 'neu', 'tfidf_pca_2', 'tfidf_pca_4',\n",
       "       'tfidf_pca_6', 'tfidf_pca_8', 'tfidf_pca_34', 'tfidf_pca_47',\n",
       "       'tfidf_pca_63', 'tfidf_pca_67', 'tfidf_pca_83', 'tfidf_pca_100',\n",
       "       'tfidf_pca_111', 'tfidf_pca_119', 'tfidf_pca_121', 'tfidf_pca_136',\n",
       "       'tfidf_pca_145', 'tfidf_pca_146'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55fb71b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['energy', 'valence', 'pos', 'neg', 'neu', 'tfidf_pca_42',\n",
       "       'tfidf_pca_47', 'tfidf_pca_49', 'tfidf_pca_60', 'tfidf_pca_62',\n",
       "       'tfidf_pca_63', 'tfidf_pca_80', 'tfidf_pca_96', 'tfidf_pca_111',\n",
       "       'tfidf_pca_114', 'tfidf_pca_115', 'tfidf_pca_123', 'tfidf_pca_124',\n",
       "       'tfidf_pca_133', 'tfidf_pca_137'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[selector2.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3bec6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>...</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>key_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.320</td>\n",
       "      <td>0.798</td>\n",
       "      <td>6</td>\n",
       "      <td>-9.660</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.00152</td>\n",
       "      <td>0.25100</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.407</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.434</td>\n",
       "      <td>0.600</td>\n",
       "      <td>5</td>\n",
       "      <td>-10.784</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.86700</td>\n",
       "      <td>0.45100</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.753</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.270</td>\n",
       "      <td>5</td>\n",
       "      <td>-11.251</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.91000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.3120</td>\n",
       "      <td>0.515</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.479</td>\n",
       "      <td>0.528</td>\n",
       "      <td>9</td>\n",
       "      <td>-10.104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.58000</td>\n",
       "      <td>0.00128</td>\n",
       "      <td>0.8140</td>\n",
       "      <td>0.185</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.639</td>\n",
       "      <td>0.893</td>\n",
       "      <td>9</td>\n",
       "      <td>-6.509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.28900</td>\n",
       "      <td>0.00816</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.966</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.320   0.798    6    -9.660     0       0.0584       0.00152   \n",
       "1         0.434   0.600    5   -10.784     0       0.0286       0.86700   \n",
       "2         0.530   0.270    5   -11.251     0       0.0365       0.91000   \n",
       "3         0.479   0.528    9   -10.104     0       0.1040       0.58000   \n",
       "4         0.639   0.893    9    -6.509     1       0.0360       0.28900   \n",
       "\n",
       "   instrumentalness  liveness  valence  ...  key_2  key_3  key_4  key_5  \\\n",
       "0           0.25100    0.0734    0.407  ...      0      0      0      0   \n",
       "1           0.45100    0.1110    0.753  ...      0      0      0      1   \n",
       "2           0.00000    0.3120    0.515  ...      0      0      0      1   \n",
       "3           0.00128    0.8140    0.185  ...      0      0      0      0   \n",
       "4           0.00816    0.2220    0.966  ...      0      0      0      0   \n",
       "\n",
       "   key_6  key_7  key_8  key_9  key_10  key_11  \n",
       "0      1      0      0      0       0       0  \n",
       "1      0      0      0      0       0       0  \n",
       "2      0      0      0      0       0       0  \n",
       "3      0      0      0      1       0       0  \n",
       "4      0      0      0      1       0       0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea06f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_mlp(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae83aaff4c47202ead0cb5b0cfe74444d437ac818c9c2cd6826845dc75a11708"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
