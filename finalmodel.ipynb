{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4851fdd4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef8168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import nltk\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error #add rmse\n",
    "from data import merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1896da",
   "metadata": {},
   "source": [
    "# Reading files and making it regressionable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e51902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/merged/merged_cleaned_sentiment_train.csv').drop(['pos','neg','neu', 'compound'], axis = 1)\n",
    "df_val = pd.read_csv('data/merged/merged_cleaned_sentiment_validation.csv').drop(['pos','neg','neu', 'compound'], axis = 1)\n",
    "df_test = pd.read_csv('data/merged/merged_cleaned_sentiment_test.csv').drop(['pos','neg','neu', 'compound'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a0c5a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['danceability', 'energy', 'instrumentalness', 'valence','mode', 'y_valence', 'y_arousal']]\n",
    "df_val = df_val[['danceability', 'energy', 'instrumentalness', 'valence','mode', 'y_valence', 'y_arousal']]\n",
    "df_test = df_test[['danceability', 'energy', 'instrumentalness', 'valence','mode','y_valence', 'y_arousal']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf147c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, pd.read_csv('data/lyrics/lyrics_features_train.csv').iloc[:, :-200]], axis=1)\n",
    "df_val = pd.concat([df_val, pd.read_csv('data/lyrics/lyrics_features_val.csv').iloc[:, :-200]], axis=1)\n",
    "df_test = pd.concat([df_test, pd.read_csv('data/lyrics/lyrics_features_test.csv').iloc[:, :-200]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943db10",
   "metadata": {},
   "source": [
    "### This was when we used all audio features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a358f",
   "metadata": {},
   "source": [
    "df_train = pd.concat([df_train, pd.get_dummies(df_train.key, drop_first = True, prefix = 'key')], axis=1)\n",
    "df_val = pd.concat([df_val, pd.get_dummies(df_val.key, drop_first = True, prefix = 'key')], axis=1)\n",
    "df_test = pd.concat([df_test, pd.get_dummies(df_val.key, drop_first = True, prefix = 'key')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512cfc24",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_train = df_train.drop(['Unnamed: 0', 'artist', 'trackname', 'id', 'time_signature', 'lyrics', 'key','lyrics_cleaned' ], axis=1)\n",
    "df_val = df_val.drop(['Unnamed: 0', 'artist', 'trackname', 'id', 'time_signature', 'lyrics', 'key', 'lyrics_cleaned' ], axis=1)\n",
    "df_test = df_test.drop(['Unnamed: 0', 'artist', 'trackname', 'id', 'time_signature', 'lyrics', 'key', 'lyrics_cleaned'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f979108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_val = df_val.dropna()\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f0a887b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['danceability', 'energy', 'instrumentalness', 'valence', 'mode',\n",
       "       'y_valence', 'y_arousal', 'Unnamed: 0', 'pos', 'neg',\n",
       "       ...\n",
       "       'tfidf_pca_91', 'tfidf_pca_92', 'tfidf_pca_93', 'tfidf_pca_94',\n",
       "       'tfidf_pca_95', 'tfidf_pca_96', 'tfidf_pca_97', 'tfidf_pca_98',\n",
       "       'tfidf_pca_99', 'tfidf_pca_100'],\n",
       "      dtype='object', length=112)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd5f2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get cross validation scores\n",
    "def get_cv_scores(model, X_train, y_train):\n",
    "    scores = cross_val_score(model,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             cv=5,\n",
    "                             scoring='r2')\n",
    "    \n",
    "    print('CV Mean: ', np.mean(scores))\n",
    "    print('STD: ', np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275770ba",
   "metadata": {},
   "source": [
    "# Splitting the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc2128c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     train set\n",
    "X_train = df_train.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "y_train_valence = df_train.y_valence.values \n",
    "y_train_arousal = df_train.y_arousal.values\n",
    "    \n",
    "#     validation set\n",
    "X_val = df_val.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "y_val_valence = df_val.y_valence.values \n",
    "y_val_arousal = df_val.y_arousal.values \n",
    "\n",
    "#      test set\n",
    "X_test = df_test.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "y_test_valence = df_test.y_valence.values \n",
    "y_test_arousal = df_test.y_arousal.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a18e096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054508397801767416"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression().fit(y_train_arousal.reshape(-1, 1), y_train_valence.reshape(-1, 1)).score(y_train_arousal.reshape(-1, 1), y_train_valence.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a867712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_regression(X, y_1, y_2, X_validation, y_1_validation, y_2_validation):\n",
    "    \n",
    "\n",
    "    # parameters\n",
    "    param_grid = {'fit_intercept':[True,False], 'positive':[True, False]}\n",
    "    \n",
    "    # Initialize model for Grid search\n",
    "    lr_val = LinearRegression()\n",
    "    lr_arou = LinearRegression()\n",
    "    \n",
    "    # Grid search\n",
    "    clf_vale = GridSearchCV(lr_val, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    clf_arou = GridSearchCV(lr_arou, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "\n",
    "    # Print best results on training data    \n",
    "    clf_vale.fit(X, y_1)\n",
    "    clf_arou.fit(X, y_2)\n",
    "    \n",
    "    # Print best results on training data\n",
    "    # add new lines to separate rows\n",
    "    print()\n",
    "    print(\"Best parameter for Valence (CV score=%0.3f):\" % clf_vale.best_score_)\n",
    "    print(clf_vale.best_params_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Best parameter for Arousal (CV score=%0.3f):\" % clf_arou.best_score_)\n",
    "    print(clf_arou.best_params_)\n",
    "    print()\n",
    "\n",
    "\n",
    "    #Initialize models with best parameters\n",
    "    lr_val_top = LinearRegression(fit_intercept=clf_vale.best_params_['fit_intercept'],  \n",
    "                                    positive = clf_vale.best_params_['positive'])\n",
    "    lr_arou_top = LinearRegression(fit_intercept=clf_arou.best_params_['fit_intercept'],  \n",
    "                                    positive = clf_arou.best_params_['positive'])\n",
    "\n",
    "    # get cross val scores for models \n",
    "    get_cv_scores(lr_val_top, X, y_1)\n",
    "    get_cv_scores(lr_arou_top, X, y_2)\n",
    "\n",
    "\n",
    "    #fit optimal models to train data \n",
    "    lr_val_fit = lr_val_top.fit(X, y_1)\n",
    "    lr_arou_fit = lr_arou_top.fit(X, y_2)\n",
    "    \n",
    "    # validation scores \n",
    "    r2_validation_valence = lr_val_fit.score(X_validation, y_1_validation)\n",
    "    r2_validation_arousal = lr_arou_fit.score(X_validation, y_2_validation)\n",
    "    \n",
    "    print()\n",
    "    print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "    print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "    \n",
    "    return clf_vale.best_params_, clf_arou.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e211ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_forest_regression(X, y_1, y_2, X_validation, y_1_validation, y_2_validation):\n",
    "    \n",
    "    # Initialize models\n",
    "    rf_val = RandomForestRegressor(random_state=0)\n",
    "    rf_arou = RandomForestRegressor(random_state=0)\n",
    "    \n",
    "    param_grid = { \n",
    "    'n_estimators': [100, 500],\n",
    "    'max_depth' : [5,10, 15]\n",
    "    }\n",
    "\n",
    "    # Grid search\n",
    "    clf_vale = GridSearchCV(rf_val, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    clf_arou = GridSearchCV(rf_arou, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "\n",
    "    # Print best results on training data    \n",
    "    clf_vale.fit(X, y_1)\n",
    "    clf_arou.fit(X, y_2)\n",
    "\n",
    "    # Print best results on training data\n",
    "    print()\n",
    "    print(\"Best parameter for Valence (CV score=%0.3f):\" % clf_vale.best_score_)\n",
    "    print(clf_vale.best_params_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Best parameter for Arousal (CV score=%0.3f):\" % clf_arou.best_score_)\n",
    "    print(clf_arou.best_params_)\n",
    "\n",
    "\n",
    "    #Initialize models with best parameters\n",
    "    rf_val_top = RandomForestRegressor(n_estimators = clf_vale.best_params_['n_estimators'], \n",
    "                                        max_depth = clf_vale.best_params_['max_depth'], random_state=0)\n",
    "    rf_arou_top = RandomForestRegressor(n_estimators = clf_arou.best_params_['n_estimators'], \n",
    "                                        max_depth = clf_arou.best_params_['max_depth'], random_state=0)\n",
    "    \n",
    "\n",
    "    # get cross val scores\n",
    "    get_cv_scores(rf_val_top, X, y_1)\n",
    "    get_cv_scores(rf_arou_top, X, y_2)\n",
    "\n",
    "    rf_val_fit = rf_val_top.fit(X, y_1)\n",
    "    rf_arou_fit = rf_arou_top.fit(X, y_2)\n",
    "    \n",
    "    r2_validation_valence = rf_val_fit.score(X_validation, y_1_validation)\n",
    "    r2_validation_arousal = rf_arou_fit.score(X_validation, y_2_validation)\n",
    "\n",
    "    print()\n",
    "    print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "    print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "    \n",
    "    \n",
    "    return clf_vale.best_params_, clf_arou.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57838728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_svr(X, y_1, y_2, X_validation, y_1_validation, y_2_validation):\n",
    "\n",
    "    # Normalization\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_validation = scaler.fit_transform(X_validation)\n",
    "\n",
    "    # Train model\n",
    "    svr_val = SVR()\n",
    "    svr_arou = SVR()\n",
    "    \n",
    "    param_grid = {'kernel' : ('linear', 'rbf', 'poly'),\n",
    "                  'C' : [1,5,10]\n",
    "                 }\n",
    "\n",
    "    # Grid search\n",
    "    clf_vale = GridSearchCV(svr_val, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    clf_arou = GridSearchCV(svr_arou, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "\n",
    "    # Print best results on training data    \n",
    "    clf_vale.fit(X, y_1)\n",
    "    clf_arou.fit(X, y_2)\n",
    "    \n",
    "    # Print best results on training data\n",
    "    # add new lines to separate rows\n",
    "    print()\n",
    "    print(\"Best parameter for Valence (CV score=%0.3f):\" % clf_vale.best_score_)\n",
    "    print(clf_vale.best_params_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Best parameter for Arousal (CV score=%0.3f):\" % clf_arou.best_score_)\n",
    "    print(clf_arou.best_params_)\n",
    "    print()\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    svr_val_top = SVR(kernel = clf_vale.best_params_['kernel'], C = clf_vale.best_params_['C'])\n",
    "    svr_arou_top = SVR(kernel = clf_arou.best_params_['kernel'], C = clf_arou.best_params_['C'])\n",
    "\n",
    "\n",
    "    # get cross val scores\n",
    "    get_cv_scores(svr_val_top, X, y_1)\n",
    "    get_cv_scores(svr_arou_top, X, y_2)\n",
    "\n",
    "    #fit\n",
    "    svr_val_fit = svr_val_top.fit(X,y_1)\n",
    "    svr_arou_fit = svr_arou_top.fit(X, y_2)\n",
    "    \n",
    "    r2_validation_valence = svr_val_fit.score(X_validation, y_1_validation)\n",
    "    r2_validation_arousal = svr_arou_fit.score(X_validation, y_2_validation)\n",
    "    \n",
    "    print()\n",
    "    print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "    print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "\n",
    "\n",
    "    return clf_vale.best_params_, clf_arou.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "467c67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mlp(X, y_1, y_2, X_validation, y_1_validation, y_2_validation):\n",
    "\n",
    "    # Normalization\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_validation = scaler.fit_transform(X_validation)\n",
    "\n",
    "    # Initialize model\n",
    "    mlp_val = MLPRegressor(random_state = 2)\n",
    "    mlp_arou = MLPRegressor(random_state = 2)\n",
    "    \n",
    "    param_grid = {'hidden_layer_sizes':[(5), (10), (15), (5,5), (10,10), (15,15), (5,5,5), (10,10,10), (15,15,15)], \n",
    "    'max_iter':[500, 1000, 2000, 2500]}\n",
    "\n",
    "    # Grid search\n",
    "    clf_vale = GridSearchCV(mlp_val, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    clf_arou = GridSearchCV(mlp_arou, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "\n",
    "\n",
    "    # Print best results on training data    \n",
    "    clf_vale.fit(X, y_1)\n",
    "    clf_arou.fit(X, y_2)\n",
    "    \n",
    "    # Print best results on training data\n",
    "    # add new lines to separate rows\n",
    "    print()\n",
    "    print(\"Best parameter for Valence (CV score=%0.3f):\" % clf_vale.best_score_)\n",
    "    print(clf_vale.best_params_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Best parameter for Arousal (CV score=%0.3f):\" % clf_arou.best_score_)\n",
    "    print(clf_arou.best_params_)\n",
    "    print()\n",
    "\n",
    "\n",
    "    #Train model with best params\n",
    "    mlp_val_top = MLPRegressor(hidden_layer_sizes=clf_vale.best_params_['hidden_layer_sizes'], max_iter=clf_vale.best_params_['max_iter'], random_state = 2)\n",
    "    mlp_arou_top = MLPRegressor(hidden_layer_sizes=clf_arou.best_params_['hidden_layer_sizes'], max_iter=clf_arou.best_params_['max_iter'], random_state = 2)\n",
    "\n",
    "    # get cross val scores \n",
    "    get_cv_scores(mlp_val_top, X, y_1)\n",
    "    get_cv_scores(mlp_arou_top, X, y_2)\n",
    "\n",
    "    mlp_val_fit = mlp_val_top.fit(X, y_1)\n",
    "    mlp_arou_fit = mlp_arou_top.fit(X, y_2)\n",
    "    \n",
    "    r2_validation_valence = mlp_val_fit.score(X_validation, y_1_validation)\n",
    "    r2_validation_arousal = mlp_arou_fit.score(X_validation, y_2_validation)\n",
    "    \n",
    "    print()\n",
    "    print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "    print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "\n",
    "    \n",
    "    return clf_vale.best_params_, clf_arou.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897b5677",
   "metadata": {},
   "source": [
    "### Random Forest Regression - Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "val_par_rf, arou_par_rf = do_forest_regression(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0b706",
   "metadata": {},
   "source": [
    "    Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
    "    Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
    "\n",
    "    Best parameter for Valence (CV score=0.185):\n",
    "    {'max_depth': 10, 'n_estimators': 500}\n",
    "\n",
    "    Best parameter for Arousal (CV score=0.199):\n",
    "    {'max_depth': 10, 'n_estimators': 500}\n",
    "    CV Mean:  0.18477634266575188\n",
    "    STD:  0.010064224970315037\n",
    "    CV Mean:  0.1987682194468258\n",
    "    STD:  0.025811738331714372\n",
    "\n",
    "    Validation score for Valence: 0.17296757628631831\n",
    "    Validation score for Arousal: 0.24101399592965878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bda13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcae7dd7",
   "metadata": {},
   "source": [
    "#### Test Set - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_val = RandomForestRegressor(n_estimators = 100, \n",
    "                                        max_depth = 5, random_state=0)\n",
    "rf_arou = RandomForestRegressor(n_estimators = 100, \n",
    "                                        max_depth = 5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e56a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_val.fit(X_train, y_train_valence).score(X_test, y_test_valence))\n",
    "print(rf_arou.fit(X_train, y_train_arousal).score(X_test, y_test_arousal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d477cd",
   "metadata": {},
   "source": [
    "### Linear Regression - optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb39853",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_par, arou_par = do_regression(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379e45b",
   "metadata": {},
   "source": [
    "    Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
    "    Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
    "\n",
    "    Best parameter for Valence (CV score=0.193):\n",
    "    {'fit_intercept': True, 'positive': False}\n",
    "\n",
    "    Best parameter for Arousal (CV score=0.164):\n",
    "    {'fit_intercept': True, 'positive': True}\n",
    "\n",
    "    CV Mean:  0.19263909417367236\n",
    "    STD:  0.01423911801666168\n",
    "    CV Mean:  0.16387005569169152\n",
    "    STD:  0.013789304326383702\n",
    "\n",
    "    Validation score for Valence: 0.18365452891704448\n",
    "    Validation score for Arousal: 0.18418929034767606"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c397f",
   "metadata": {},
   "source": [
    "#### LR Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_val = LinearRegression(fit_intercept=val_par['fit_intercept'],  \n",
    "                                    positive = val_par['positive'])\n",
    "lr_arou = LinearRegression(fit_intercept=arou_par['fit_intercept'],  \n",
    "                                    positive = arou_par['positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_val.fit(X_train, y_train_valence).score(X_test, y_test_valence))\n",
    "print(lr_arou.fit(X_train, y_train_arousal).score(X_test, y_test_arousal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be573fb",
   "metadata": {},
   "source": [
    "### Support Vector Regression - optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_par_svr, arou_par_svr = do_svr(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e747b46",
   "metadata": {},
   "source": [
    "#### Test Score - SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_val = SVR(kernel = val_par_svr['kernel'], C = val_par_svr['C'])\n",
    "svr_arou = SVR(kernel = arou_par_svr['kernel'], C = arou_par_svr['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c389c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svr_val.fit(X_train, y_train_valence).score(X_test, y_test_valence))\n",
    "print(svr_arou.fit(X_train, y_train_arousal).score(X_test, y_test_arousal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360deed0",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Regression - optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f3a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_par_mlp, arou_par_mlp = do_mlp(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18724bea",
   "metadata": {},
   "source": [
    "    Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
    "    Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
    "\n",
    "    Best parameter for Valence (CV score=0.198):\n",
    "    {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 500}\n",
    "\n",
    "    Best parameter for Arousal (CV score=0.177):\n",
    "    {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 500}\n",
    "\n",
    "    CV Mean:  0.19816558523065714\n",
    "    STD:  0.013616324243766003\n",
    "    CV Mean:  0.17746596775912477\n",
    "    STD:  0.022757705925352777\n",
    "\n",
    "    Validation score for Valence: 0.16755552530343532\n",
    "    Validation score for Arousal: 0.2115436506271312\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f83a62",
   "metadata": {},
   "source": [
    "### Test Set - MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32971f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_val = MLPRegressor(hidden_layer_sizes=val_par_mlp['hidden_layer_sizes'], max_iter=val_par_mlp['max_iter'], random_state = 2)\n",
    "mlp_arou = MLPRegressor(hidden_layer_sizes=arou_par_mlp['hidden_layer_sizes'], max_iter=arou_par_mlp['max_iter'], random_state = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65496288",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c597109",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlp_val.fit(X_train, y_train_valence).score(X_test, y_test_valence))\n",
    "print(mlp_arou.fit(X_train, y_train_arousal).score(X_test, y_test_arousal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b93966",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66892e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44659e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in [5,10,15,20,25]:\n",
    "\n",
    "    print(i, 'FEATURES')\n",
    "    estimator = LinearRegression(fit_intercept= True, positive= True)\n",
    "    selector = RFE(estimator, n_features_to_select=i, step=1)\n",
    "    selector = selector.fit(X_train, y_train_valence)\n",
    "\n",
    "    estimator2 = LinearRegression(fit_intercept= True, positive= True)\n",
    "    selector2 = RFE(estimator2, n_features_to_select=i, step=1)\n",
    "    selector_arou = selector2.fit(X_train, y_train_arousal)\n",
    "\n",
    "    lr_valence = LinearRegression(fit_intercept= True, positive= True)\n",
    "    lr_arousal = LinearRegression(fit_intercept= True, positive= True)\n",
    "    get_cv_scores(estimator, X_train[:,selector.support_], y_train_valence)\n",
    "    get_cv_scores(estimator, X_train[:,selector_arou.support_], y_train_arousal)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 features\n",
    "estimator = LinearRegression(fit_intercept= True, positive= True)\n",
    "selector = RFE(estimator, n_features_to_select=20, step=1)\n",
    "selector = selector.fit(X_train, y_train_valence)\n",
    "\n",
    "estimator2 = LinearRegression(fit_intercept= True, positive= True)\n",
    "selector2 = RFE(estimator2, n_features_to_select=20, step=1)\n",
    "selector_arou = selector2.fit(X_train, y_train_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbf3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_valence = MLPRegressor(hidden_layer_sizes= (10,10), max_iter=500)\n",
    "mlp_arousal = MLPRegressor(hidden_layer_sizes= 5, max_iter=500)\n",
    "mlp_val_fit = mlp_valence.fit(X_train[:,selector.support_], y_train_valence)\n",
    "mlp_arou_fit = mlp_arousal.fit(X_train[:,selector_arou.support_], y_train_arousal)\n",
    "\n",
    "r2_validation_valence = mlp_val_fit.score(X_val[:,selector.support_], y_val_valence)\n",
    "r2_validation_arousal = mlp_arou_fit.score(X_val[:,selector_arou.support_], y_val_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465cde19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print()\n",
    "print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "print(f'Validation score for Arousal: {r2_validation_arousal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ec7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns[selector2.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bec6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea06f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_mlp(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5a620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
